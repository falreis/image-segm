{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, argparse, numpy as np, math, sys, copy\n",
    "from skimage.segmentation import slic, mark_boundaries, felzenszwalb\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import superpixels as sp\n",
    "import plot as pl\n",
    "import process_ground_truth as pgt\n",
    "import glob\n",
    "import eval_boundary as ev\n",
    "import pipeline as pipe\n",
    "import time\n",
    "import superpixels as sp\n",
    "import scipy.stats as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_path = 'BSDS500/data/groundTruth/val/'\n",
    "train_path = 'BSDS500/data/images/val/'\n",
    "save_path = 'save/'\n",
    "bound_prefix = 'images/'\n",
    "eval_prefix = 'eval/'\n",
    "extension = '.npz'\n",
    "\n",
    "epsilon = 0.0001 #just to round down\n",
    "number_clusters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "len_ground = len(ground_path)\n",
    "ground_files = glob.glob(ground_path + '*.mat')\n",
    "ground_filenames = [x[len_ground:-4] for x in ground_files]\n",
    "\n",
    "groundtruths, images, names = [], [], []\n",
    "\n",
    "#load images\n",
    "for filename in ground_filenames:\n",
    "    ground_file = ground_path + filename + '.mat'\n",
    "    train_file = train_path + filename + '.jpg'\n",
    "    \n",
    "    #read groundtruth and image\n",
    "    groundtruth = pgt.get_groundTruth(ground_file)\n",
    "    image = img_as_float(io.imread(train_file))\n",
    "    \n",
    "    #append image and groundtruths\n",
    "    groundtruths.append(groundtruth)\n",
    "    images.append(image)\n",
    "    names.append(filename + '.png')\n",
    "    \n",
    "print(len(groundtruths), len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate boundaries and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [40, 32, 24, 16, 8]\n",
      "20 [40, 32, 24, 16, 8]\n",
      "30 [40, 32, 24, 16, 8]\n",
      "40 [40, 32, 24, 16, 8]\n",
      "50 [40, 32, 24, 16, 8]\n",
      "60 [40, 32, 24, 16, 8]\n",
      "70 [40, 32, 24, 16, 8]\n",
      "80 [40, 32, 24, 16, 8]\n",
      "90 [40, 32, 24, 16, 8]\n",
      "100 [40, 32, 24, 16, 8]\n",
      "409.91629433631897 seconds\n"
     ]
    }
   ],
   "source": [
    "ini = 0\n",
    "fim = len(ground_filenames)\n",
    "\n",
    "methods = ['hsgb'] #['hslic', 'hsgb', 'hegb']\n",
    "\n",
    "for method in methods:\n",
    "    last_shape = None\n",
    "    blank_image = None\n",
    "    index = 0\n",
    "    \n",
    "    starttime = time.time()\n",
    "    for image, name in zip(images[ini:fim], names[ini:fim]):\n",
    "        if(image.shape != last_shape):\n",
    "            blank_image = np.zeros(image.shape,dtype=np.uint8) #create blank image to save\n",
    "            blank_image.fill(255)\n",
    "            last_shape = image.shape\n",
    "        \n",
    "        ##generate ultrametric map\n",
    "        ultra_image, cluster_sizes = pipe.generate_ultrametric_image(image, blank_image, method)\n",
    "        \n",
    "        #convert to grayscale\n",
    "        gray_image = np.dot(ultra_image[...,:3], [0.299, 0.587, 0.114])\n",
    "        \n",
    "        #save image\n",
    "        boundname = save_path + method + '/' + bound_prefix + name\n",
    "        io.imsave(boundname, gray_image)\n",
    "        \n",
    "        #verbose mode\n",
    "        index += 1\n",
    "        if index % 10 == 0:\n",
    "            print(index, cluster_sizes)\n",
    "\n",
    "    endtime = time.time()\n",
    "        \n",
    "    #np.savez(boundname, borders=borders)\n",
    "    print((endtime - starttime), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover boundaries and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "169.21013498306274 seconds\n"
     ]
    }
   ],
   "source": [
    "ini = 0\n",
    "fim = len(ground_filenames)\n",
    "\n",
    "methods = ['hsgb'] #['hslic', 'hsegb', 'hegb']\n",
    "\n",
    "for method in methods:    \n",
    "    threshold = 0\n",
    "    index = 0\n",
    "\n",
    "    starttime = time.time()\n",
    "    \n",
    "    for groundtruth, name in zip(groundtruths[ini:fim], names[ini:fim]):\n",
    "        precisions, recalls = [], []\n",
    "        \n",
    "        boundname = save_path + method + '/' + bound_prefix + name\n",
    "        evalname = save_path + method + '/' + eval_prefix + name + extension\n",
    "        \n",
    "        image = img_as_float(io.imread(boundname))        \n",
    "        unique = np.unique(image)\n",
    "        \n",
    "        #adjust number of clusters (only to some itens)\n",
    "        if(len(unique) <= number_clusters):\n",
    "            len_unique = len(unique)\n",
    "            for i in range(number_clusters-len_unique+1):\n",
    "                unique = np.append(unique, unique[len_unique-1])\n",
    "        \n",
    "        for thresh in unique[1:]:\n",
    "            thresh_image = sci.threshold(image, (thresh - epsilon))\n",
    "\n",
    "            #calculate values from precision and recall\n",
    "            precision, recall = ev.eval_bound(groundtruth[:,:,0], thresh_image, threshold, True)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "        \n",
    "        #verbose mode\n",
    "        index += 1\n",
    "        if index % 10 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        #save precision file\n",
    "        np.savez(evalname, precisions=precisions, recalls=recalls)\n",
    "            \n",
    "    endtime = time.time()\n",
    "    print((endtime - starttime), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load evaluations and calculate f-measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15525036  0.20788418  0.2280259   0.23445528  0.23834142]\n"
     ]
    }
   ],
   "source": [
    "ini = 0\n",
    "fim = len(ground_filenames)\n",
    "\n",
    "methods = ['hsgb'] #['hslic', 'hsegb', 'hegb']\n",
    "\n",
    "for method in methods:\n",
    "    precisions, recalls = [], []\n",
    "    fmeasures = []\n",
    "    \n",
    "    for name in names[ini:fim]:\n",
    "        evalname = save_path + method + '/' + eval_prefix + name + extension\n",
    "        npload = np.load(evalname)\n",
    "        precisions.append(npload['precisions'])\n",
    "        recalls.append(npload['recalls'])\n",
    "\n",
    "    for i in range(0,len(precisions[0])):\n",
    "        cutz_precision, cutz_recall = [], []\n",
    "        \n",
    "        for precision, recall in zip(precisions, recalls):\n",
    "            cutz_precision.append(precision[i])\n",
    "            cutz_recall.append(recall[i])\n",
    "    \n",
    "        np_precisions = (np.array(cutz_precision))\n",
    "        np_recalls = (np.array(cutz_recall))\n",
    "\n",
    "        fmeasure = 2 * ((np_precisions * np_recalls) / (np_precisions + np_recalls))\n",
    "        fmeasures.append(fmeasure)\n",
    "    \n",
    "    #print(fmeasures)\n",
    "print(np.average(fmeasures, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
